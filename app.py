import streamlit as st
import requests
import pandas as pd
from io import StringIO, BytesIO
import urllib.request
import altair as alt
import re
import base64 # Th∆∞ vi·ªán ƒë·ªÉ chuy·ªÉn ƒë·ªïi ·∫£nh
from pathlib import Path # Th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n file

# Th∆∞ vi·ªán cho t√≠nh nƒÉng gi·ªçng n√≥i
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from pydub import AudioSegment
from gtts import gTTS

# --- C·∫•u h√¨nh ---
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except (FileNotFoundError, KeyError):
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY. Vui l√≤ng th√™m v√†o m·ª•c Secrets.")
    st.stop()

GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1/models/gemini-2.5-flash:generateContent"

# --- THAY ƒê·ªîI: H√†m ƒë·ªÉ chuy·ªÉn ƒë·ªïi ·∫£nh sang Base64 ---
@st.cache_data
def get_image_as_base64(path: Path) -> str:
    """H√†m n√†y ƒë·ªçc file ·∫£nh v√† chuy·ªÉn n√≥ th√†nh chu·ªói Base64."""
    try:
        with open(path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y file ·∫£nh t·∫°i ƒë∆∞·ªùng d·∫´n: {path}")
        return ""

# --- THAY ƒê·ªîI: H√†m ƒë·ªÉ t·∫°o v√† √°p d·ª•ng CSS t√πy ch·ªânh ---
def apply_custom_css():
    """H√†m n√†y t·∫°o ra m√£ CSS ƒë·ªÉ thay th·∫ø icon c·ªßa n√∫t mic."""
    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file ·∫£nh c·ªßa b·∫°n
    start_icon_path = Path("assets/oppenmic.png")
    stop_icon_path = Path("aassets/closemic.png")

    # Chuy·ªÉn ·∫£nh sang Base64
    start_icon_b64 = get_image_as_base64(start_icon_path)
    stop_icon_b64 = get_image_as_base64(stop_icon_path)

    if not start_icon_b64 or not stop_icon_b64:
        st.warning("Kh√¥ng th·ªÉ √°p d·ª•ng icon t√πy ch·ªânh do kh√¥ng t√¨m th·∫•y file ·∫£nh.")
        return

    custom_css = f"""
    <style>
        /* T√¨m ƒë·∫øn n√∫t b·∫•m c·ªßa mic recorder */
        div[data-testid="stToolbar"] button[title*="Start recording"], div[data-testid="stToolbar"] button[title*="Stop recording"] {{
            /* ·∫®n icon m·∫∑c ƒë·ªãnh (n·∫øu c√≥) v√† ch·ªØ */
            color: transparent !important;
            background-repeat: no-repeat;
            background-position: center;
            background-size: contain; /* Ho·∫∑c 'cover' t√πy theo ·∫£nh c·ªßa b·∫°n */
            border: none !important; /* X√≥a vi·ªÅn */
            width: 32px; /* K√≠ch th∆∞·ªõc n√∫t */
            height: 32px;
        }}

        /* Icon cho tr·∫°ng th√°i "Start" */
        div[data-testid="stToolbar"] button[title*="Start recording"] {{
            background-image: url(data:image/png;base64,{start_icon_b64});
        }}
        
        /* Icon cho tr·∫°ng th√°i "Stop" */
        div[data-testid="stToolbar"] button[title*="Stop recording"] {{
            background-image: url(data:image/png;base64,{stop_icon_b64});
        }}
    </style>
    """
    st.markdown(custom_css, unsafe_allow_html=True)

# --- C√°c h√†m kh√°c kh√¥ng thay ƒë·ªïi ---
def clean_text_for_speech(text: str) -> str:
    text = re.sub(r'\*\*', '', text)
    text = re.sub(r'\*', '', text)
    text = re.sub(r'^\s*-\s*', '', text, flags=re.MULTILINE)
    text = text.replace(':', ',')
    return text

def text_to_speech(text: str, language: str = 'vi'):
    try:
        cleaned_text = clean_text_for_speech(text)
        tts = gTTS(text=cleaned_text, lang=language, slow=False)
        fp = BytesIO()
        tts.write_to_fp(fp)
        fp.seek(0)
        return fp
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o √¢m thanh: {e}")
        return None

@st.cache_data(ttl=300)
def load_data_from_sheets(sheet_key):
    # ... (gi·ªØ nguy√™n m√£ c·ªßa h√†m n√†y)
    if not sheet_key:
        return None
    url = f"https://docs.google.com/spreadsheets/d/{sheet_key}/export?format=csv&gid=0"
    try:
        df = pd.read_csv(url)
        df.columns = df.columns.str.strip()
        required_columns = ['Date', 'T√¨nh tr·∫°ng l√∫a', 'm·ª©c ƒë·ªô nhi·ªÖm']
        if not all(col in df.columns for col in required_columns):
            st.error(f"L·ªói: File Sheets ph·∫£i ch·ª©a c√°c c·ªôt: {', '.join(required_columns)}")
            return None
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date
        df.dropna(subset=['Date'], inplace=True)
        st.success(f"ƒê√£ t·∫£i v√† x·ª≠ l√Ω {len(df)} d√≤ng d·ªØ li·ªáu t·ª´ Sheets.")
        return df.sort_values(by='Date')
    except Exception as e:
        st.error(f"L·ªói t·∫£i d·ªØ li·ªáu t·ª´ Sheets: {e}")
        return None

@st.cache_data
def calculate_disease_scores(df):
    # ... (gi·ªØ nguy√™n m√£ c·ªßa h√†m n√†y)
    if df is None or df.empty:
        return pd.DataFrame(), []
    disease_names = [d for d in df['T√¨nh tr·∫°ng l√∫a'].unique() if d not in ['healthy', 'Kh·ªèe m·∫°nh', 'Kh√¥ng x√°c ƒë·ªãnh']]
    scores = {name: 0 for name in disease_names}
    scores_over_time = []
    for index, row in df.iterrows():
        date = row['Date']
        tinh_trang = row['T√¨nh tr·∫°ng l√∫a']
        muc_do = row['m·ª©c ƒë·ªô nhi·ªÖm']
        if tinh_trang in ['healthy', 'Kh·ªèe m·∫°nh'] or muc_do == 'kh√¥ng nhi·ªÖm b·ªánh':
            for disease in scores:
                scores[disease] = max(0, scores[disease] - 1)
        elif tinh_trang in disease_names:
            if muc_do == 'M·ªõi nhi·ªÖm':
                scores[tinh_trang] += 3
            elif muc_do == 'Nhi·ªÖm v·ª´a':
                scores[tinh_trang] += 4
            elif muc_do == 'Nhi·ªÖm n·∫∑ng':
                scores[tinh_trang] += 9
        for disease in scores:
             if scores[disease] > 10: scores[disease] = 10
             if scores[disease] < 0: scores[disease] = 0
        current_scores = {'Record_ID': index, 'Date': date, **scores}
        scores_over_time.append(current_scores)
    scores_df = pd.DataFrame(scores_over_time)
    warnings = []
    if not scores_df.empty:
        last_scores = scores_df.iloc[-1]
        for disease, score in last_scores.items():
            if disease not in ['Record_ID', 'Date'] and score > 5:
                warnings.append(f"B·ªánh '{disease}' ƒë√£ v∆∞·ª£t ng∆∞·ª°ng c·∫£nh b√°o v·ªõi {score} ƒëi·ªÉm!")
    return scores_df, warnings

def analyze_scores_for_chatbot(scores_df):
    # ... (gi·ªØ nguy√™n m√£ c·ªßa h√†m n√†y)
    if scores_df is None or scores_df.empty:
        return "Hi·ªán kh√¥ng c√≥ d·ªØ li·ªáu ƒëi·ªÉm nguy hi·ªÉm ƒë·ªÉ ph√¢n t√≠ch."
    latest_scores = scores_df.iloc[-1]
    latest_date = latest_scores['Date'].strftime('%d-%m-%Y')
    disease_cols = [col for col in scores_df.columns if col not in ['Date', 'Record_ID']]
    summary_text = f"B√°o c√°o ph√¢n t√≠ch di·ªÖn bi·∫øn ƒëi·ªÉm nguy hi·ªÉm (t√≠nh ƒë·∫øn ng√†y {latest_date}):\n\n"
    summary_text += "**1. ƒêi·ªÉm s·ªë hi·ªán t·∫°i:**\n"
    for disease in disease_cols:
        score = latest_scores[disease]
        summary_text += f"- {disease}: {score} ƒëi·ªÉm.\n"
    summary_text += "\n**2. Ph√¢n t√≠ch xu h∆∞·ªõng g·∫ßn ƒë√¢y:**\n"
    if len(scores_df) > 1:
        for disease in disease_cols:
            recent_scores = scores_df[disease].tail(5)
            if len(recent_scores) > 2:
                trend_start = recent_scores.iloc[0]
                trend_end = recent_scores.iloc[-1]
                if trend_end > trend_start:
                    trend = "c√≥ xu h∆∞·ªõng **TƒÇNG**."
                elif trend_end < trend_start:
                    trend = "c√≥ xu h∆∞·ªõng **GI·∫¢M**."
                else:
                    trend = "ƒëang **·ªîN ƒê·ªäNH**."
            else:
                trend = "ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch xu h∆∞·ªõng."
            summary_text += f"- {disease}: {trend}\n"
    else:
        summary_text += "- Ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch xu h∆∞·ªõng.\n"
    return summary_text

def call_gemini_api(summary_report, user_prompt, history=""):
    # ... (gi·ªØ nguy√™n m√£ c·ªßa h√†m n√†y)
    system_prompt = f"""
B·∫°n l√† CHTN, m·ªôt tr·ª£ l√Ω AI n√¥ng nghi·ªáp chuy√™n ph√¢n t√≠ch bi·ªÉu ƒë·ªì v√† d·ªØ li·ªáu di·ªÖn bi·∫øn. D·ª±a v√†o "B√°o c√°o ph√¢n t√≠ch di·ªÖn bi·∫øn ƒëi·ªÉm nguy hi·ªÉm" d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi ng∆∞·ªùi d√πng nh∆∞ m·ªôt chuy√™n gia.
QUY T·∫ÆC:
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·∫≠p trung v√†o th√¥ng tin quan tr·ªçng nh·∫•t.
- Khi ƒë∆∞·ª£c h·ªèi v·ªÅ t√¨nh h√¨nh chung, h√£y t√≥m t·∫Øt b√°o c√°o, t·∫≠p trung v√†o c√°c b·ªánh c√≥ ƒëi·ªÉm s·ªë cao v√† xu h∆∞·ªõng TƒÇNG. ƒê∆∞a ra nh·∫≠n ƒë·ªãnh t·ªïng quan.
- Khi ƒë∆∞·ª£c h·ªèi c·ª• th·ªÉ v·ªÅ m·ªôt b·ªánh, h√£y d·ª±a v√†o ƒëi·ªÉm s·ªë v√† xu h∆∞·ªõng c·ªßa b·ªánh ƒë√≥ ƒë·ªÉ tr·∫£ l·ªùi chi ti·∫øt.
- Ch·ªß ƒë·ªông ƒë∆∞a ra l·ªùi khuy√™n d·ª±a tr√™n ph√¢n t√≠ch. V√≠ d·ª•: "ƒêi·ªÉm b·ªánh ƒë·∫°o √¥n ƒëang c√≥ xu h∆∞·ªõng tƒÉng nhanh, b√°c n√™n ∆∞u ti√™n thƒÉm ƒë·ªìng v√† ki·ªÉm tra c√°c d·∫•u hi·ªáu c·ªßa b·ªánh n√†y."
- N·∫øu ng∆∞·ªùi d√πng ch√†o h·ªèi, h√£y ch√†o l·∫°i th√¢n thi·ªán v√† t√≥m t·∫Øt ng·∫Øn g·ªçn t√¨nh h√¨nh n·ªïi b·∫≠t nh·∫•t (v√≠ d·ª•: b·ªánh n√†o ƒëang c√≥ ƒëi·ªÉm cao nh·∫•t).
- Lu√¥n tr·∫£ l·ªùi d·ª±a tr√™n b√°o c√°o ƒë∆∞·ª£c cung c·∫•p.
---
**B√ÅO C√ÅO PH√ÇN T√çCH DI·ªÑN BI·∫æN ƒêI·ªÇM NGUY HI·ªÇM (D·ªØ li·ªáu ch√≠nh ƒë·ªÉ ph√¢n t√≠ch)**
{summary_report}
---
L·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn ƒë√¢y: {history}
C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: "{user_prompt}"
"""
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": system_prompt}]}]}
    try:
        response = requests.post(f"{GEMINI_API_URL}?key={GEMINI_API_KEY}", headers=headers, json=data, timeout=60)
        response.raise_for_status()
        result = response.json()
        return result['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        return f"L·ªói g·ªçi API: {e}"

# --- Giao di·ªán ·ª©ng d·ª•ng Streamlit ---
st.title("WED H·ªÜ TH·ªêNG GI√ÅM S√ÅT & CHU·∫®N ƒêO√ÅN B·ªÜNH ·ªû L√∫a CHTN")

# --- THAY ƒê·ªîI: √Åp d·ª•ng CSS t√πy ch·ªânh ngay t·ª´ ƒë·∫ßu ---
apply_custom_css()

# --- Chuy·ªÉn n√∫t b·∫•m Mic v√†o Sidebar ---
audio_data = None
with st.sidebar:
    st.header("C·∫•u h√¨nh")
    st.text_input("Google Sheets Key", value="1JBoW6Wnv6satuZHlNXgJP0lzRXhSqgYRTrWeBJTKk60", disabled=True)
    
    conversation_mode = st.toggle(
        "Ch·∫ø ƒë·ªô ƒë√†m tho·∫°i", 
        value=True, 
        help="Khi ƒë∆∞·ª£c b·∫≠t, c√¢u tr·∫£ l·ªùi c·ªßa AI s·∫Ω t·ª± ƒë·ªông ph√°t."
    )
    
    st.markdown("---")
    st.write("**Tr√≤ chuy·ªán b·∫±ng gi·ªçng n√≥i:**")
    # --- THAY ƒê·ªîI: X√≥a prompt ƒë·ªÉ CSS c√≥ th·ªÉ thay th·∫ø ho√†n to√†n ---
    audio_data = mic_recorder(start_prompt="&nbsp;", stop_prompt="&nbsp;", key='mic_recorder', use_container_width=True)
    st.markdown("---")

    if st.button("T·∫£i l·∫°i & Ph√¢n t√≠ch d·ªØ li·ªáu"):
        st.cache_data.clear()
        st.rerun()
    if st.button("X√≥a l·ªãch s·ª≠ chat"):
        st.session_state.messages = []
        if 'last_audio_id' in st.session_state:
            del st.session_state['last_audio_id']
        st.rerun()

# --- C√°c ph·∫ßn c√≤n l·∫°i gi·ªØ nguy√™n ---
# (D√°n ph·∫ßn c√≤n l·∫°i c·ªßa file app.py c·ªßa b·∫°n v√†o ƒë√¢y)
df_data = load_data_from_sheets("1JBoW6Wnv6satuZHlNXgJP0lzRXhSqgYRTrWeBJTKk60")
scores_df, warnings = calculate_disease_scores(df_data)
data_for_chatbot = analyze_scores_for_chatbot(scores_df)

if scores_df is not None and not scores_df.empty:
    with st.expander("Xem bi·ªÉu ƒë·ªì ƒëi·ªÉm nguy hi·ªÉm c·ªßa b·ªánh", expanded=True):
        min_date = scores_df['Date'].min()
        max_date = scores_df['Date'].max()
        start_date, end_date = st.slider(
            "Ch·ªçn kho·∫£ng ng√†y b·∫°n mu·ªën xem:",
            min_value=min_date,
            max_value=max_date,
            value=(min_date, max_date),
            format="DD/MM/YYYY"
        )
        filtered_df = scores_df[(scores_df['Date'] >= start_date) & (scores_df['Date'] <= end_date)]
        if not filtered_df.empty:
            scores_melted = filtered_df.melt(id_vars=['Record_ID', 'Date'], var_name='T√™n b·ªánh', value_name='ƒêi·ªÉm nguy hi·ªÉm')
            rule = alt.Chart(pd.DataFrame({'y': [5]})).mark_rule(color='red', strokeDash=[5,5]).encode(y='y')
            line_chart = alt.Chart(scores_melted).mark_line().encode(
                x=alt.X('Record_ID', title='D√≤ng d·ªØ li·ªáu (theo th·ªùi gian)'),
                y=alt.Y('ƒêi·ªÉm nguy hi·ªÉm', scale=alt.Scale(domain=[0, 10])),
                color='T√™n b·ªánh',
                tooltip=['Date', 'T√™n b·ªánh', 'ƒêi·ªÉm nguy hi·ªÉm']
            ).interactive()
            final_chart = (line_chart + rule).properties(
                title='Di·ªÖn bi·∫øn ƒëi·ªÉm nguy hi·ªÉm c·ªßa c√°c lo·∫°i b·ªánh theo t·ª´ng c·∫≠p nh·∫≠t'
            )
            st.altair_chart(final_chart, use_container_width=True)
        else:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã trong kho·∫£ng ng√†y ƒë√£ ch·ªçn.")

if "messages" not in st.session_state:
    st.session_state.messages = []
    initial_msg = "Ch√†o b√°c, con l√† AI CHTN. Con s·∫Ω theo d√µi v√† c·∫£nh b√°o n·∫øu c√≥ d·ªãch b·ªánh nguy hi·ªÉm."
    st.session_state.messages.append({"role": "assistant", "content": initial_msg})
    if warnings:
        warning_text = "‚ö†Ô∏è **C·∫¢NH B√ÅO KH·∫®N!**\n\n" + "\n".join(f"- {w}" for w in warnings)
        st.session_state.messages.append({"role": "assistant", "content": warning_text})

user_input = None

if audio_data and st.session_state.get('last_audio_id') != audio_data['id']:
    st.session_state.last_audio_id = audio_data['id']
    try:
        audio_bytes = BytesIO(audio_data['bytes'])
        audio_segment = AudioSegment.from_file(audio_bytes)
        r = sr.Recognizer()
        with BytesIO() as wav_file:
            audio_segment.export(wav_file, format="wav")
            wav_file.seek(0)
            with sr.AudioFile(wav_file) as source:
                audio = r.record(source)
        user_input = r.recognize_google(audio, language="vi-VN")
    except sr.UnknownValueError:
        st.toast("Con kh√¥ng nghe r√µ, b√°c th·ª≠ l·∫°i nh√©!", icon="ü§î")
    except Exception as e:
        st.error(f"ƒê√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω gi·ªçng n√≥i: {e}")

if text_input := st.chat_input("Ho·∫∑c nh·∫≠p tin nh·∫Øn t·∫°i ƒë√¢y..."):
    user_input = text_input

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages[-5:]])
    response = call_gemini_api(data_for_chatbot, user_input, history)
    audio_file = text_to_speech(response)
    
    assistant_message = {"role": "assistant", "content": response}
    
    if conversation_mode and audio_file:
        st.session_state.autoplay_audio = audio_file
    elif audio_file:
        assistant_message["manual_audio"] = audio_file
        
    st.session_state.messages.append(assistant_message)
    
    st.rerun()

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "manual_audio" in message:
            st.audio(message["manual_audio"], format='audio/mp3')

if "autoplay_audio" in st.session_state and st.session_state.autoplay_audio:
    st.audio(st.session_state.autoplay_audio, format='audio/mp3', autoplay=True)
    del st.session_state.autoplay_audio
